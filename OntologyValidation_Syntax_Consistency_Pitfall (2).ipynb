{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lTOsRmge6FO"
      },
      "outputs": [],
      "source": [
        "turtle_ontology_path = \"/content/HabitatAquaDivaOntology (3).ttl\"\n",
        "ontology_path = \"/content/HabitatAquaDivaOntology(3)\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuilurULuxcC"
      },
      "source": [
        "# Syntax Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Z1pP-7NzZG",
        "outputId": "979686ba-eb8e-4736-dbac-922ae80b3d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdflib\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.1.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n",
            "Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.6.1 rdflib-7.0.0\n"
          ]
        }
      ],
      "source": [
        "#Syntax Check\n",
        "!pip install rdflib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjlTZy8rJHtk",
        "outputId": "50824d1b-b777-4fab-d81c-fa688029b666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AquaDiva2(2).ttl\n",
            "Turtle syntax is correct.\n"
          ]
        }
      ],
      "source": [
        "from rdflib import Graph\n",
        "\n",
        "def read_turtle_file_as_string(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        print(file_path)\n",
        "        turtle_content = file.read()\n",
        "    return turtle_content\n",
        "\n",
        "\n",
        "file_path = turtle_ontology_path\n",
        "turtle_data = read_turtle_file_as_string(file_path)\n",
        "\n",
        "#turtle_data = \"\"\"\n",
        "\n",
        "\n",
        "\n",
        " #\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "g = Graph()\n",
        "\n",
        "try:\n",
        "    g.parse(data=turtle_data, format=\"turtle\")\n",
        "    print(\"Turtle syntax is correct.\")\n",
        "except Exception as e:  # This catches any exception, including BadSyntax and ParserError\n",
        "    print(f\"Error parsing Turtle file: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx8A5r7Cim2Y"
      },
      "source": [
        "# Consistency Check with HermiT and Pellet reasoner\n",
        "\n",
        "https://owlready2.readthedocs.io/en/latest/reasoning.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOB3k86PuQIn"
      },
      "outputs": [],
      "source": [
        "#Helper Convert .ttl to .xml OWL/XML ontology\n",
        "\n",
        "\n",
        "def convert_ttl_to_xml(ttl_file_path, xml_file_path):\n",
        "    # Create an empty Graph\n",
        "    g = Graph()\n",
        "\n",
        "    # Parse the .ttl file\n",
        "    g.parse(ttl_file_path, format='turtle')\n",
        "\n",
        "    # Serialize the Graph to .xml format\n",
        "    g.serialize(destination=xml_file_path, format='xml')\n",
        "\n",
        "# Example usage\n",
        "ttl_file_path = turtle_ontology_path\n",
        "xml_file_path = ontology_path+'.xml'\n",
        "convert_ttl_to_xml(ttl_file_path, xml_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Graph\n",
        "\n",
        "# Define the input and output file paths\n",
        "input_file = \"/content/original.owl\"  # Replace with your .owl file path\n",
        "output_file = \"/content/original.xml\"  # Replace with your desired .xml file path\n",
        "\n",
        "# Create an RDF graph\n",
        "g = Graph()\n",
        "\n",
        "# Parse the OWL file (in RDF/XML format)\n",
        "g.parse(input_file, format=\"xml\")\n",
        "\n",
        "# Serialize the graph into plain XML format (RDF/XML)\n",
        "g.serialize(destination=output_file, format=\"xml\")\n",
        "\n",
        "print(f\"Conversion complete! RDF/XML saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpQOTzBTOX1i",
        "outputId": "32062b01-a293-4233-a752-b08d06073792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rdflib.term:http://purl.jp/bio/4/id/200906092801729124#Molecular marker does not look like a valid URI, trying to serialize this will break.\n",
            "WARNING:rdflib.term:http://purl.jp/bio/4/id/201206044053997618#ammonia oxidizing archaea does not look like a valid URI, trying to serialize this will break.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion complete! RDF/XML saved to /content/original.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To-VoX0cXzoZ",
        "outputId": "bbd9d799-00be-45cb-eb6d-26d26863c9bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: owlready2 in /usr/local/lib/python3.10/dist-packages (0.46)\n"
          ]
        }
      ],
      "source": [
        "!pip install owlready2 --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2EVmcKbXwYf"
      },
      "outputs": [],
      "source": [
        "#Loading XML ontology\n",
        "#from owlready2 import *\n",
        "\n",
        "#def load_ontology(file_path):\n",
        " #   try:\n",
        "  #      onto = get_ontology(file_path).load()\n",
        "   #     print(\"Ontology loaded successfully.\")\n",
        "   # except OwlReadyOntologyParsingError as e:\n",
        "    #    print(f\"Failed to load ontology due to parsing error: {str(e)}\")\n",
        "\n",
        "#def main():\n",
        " #   file_path = \"/content/example3.xml\"  # Update this to your actual file path\n",
        "  #  load_ontology(file_path)\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        " #   main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60hr1lKFwFdn",
        "outputId": "39fa6d43-9492-4fb7-da66-83ff766b3d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "It all went pear-shaped: Could not load imported ontology: <http://www.w3.org/2002/07/owl#> Cause: Problem parsing http://www.w3.org/2002/07/owl#\n",
            "Could not parse ontology.  Either a suitable parser could not be found, or parsing failed.  See parser logs below for explanation.\n",
            "The following parsers were tried:\n",
            "1) RDFXMLParser\n",
            "2) OWLXMLParser\n",
            "3) OWLFunctionalSyntaxOWLParser\n",
            "4) TurtleOntologyParser\n",
            "5) OWLOBOParser\n",
            "6) KRSS2OWLParser\n",
            "7) ManchesterOWLSyntaxOntologyParser\n",
            "\n",
            "\n",
            "Detailed logs:\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: RDFXMLParser\n",
            "org.semanticweb.owlapi.rdf.syntax.RDFParserException: [line=1:column=7] Expecting rdf:RDF element.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: OWLXMLParser\n",
            "org.xml.sax.SAXParseException; systemId: http://www.w3.org/2002/07/owl#; lineNumber: 6; columnNumber: 3; The element type \"hr\" must be terminated by the matching end-tag \"</hr>\".\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: OWLFunctionalSyntaxOWLParser\n",
            "Encountered \" <FULLIRI> \"<html> \"\" at line 1, column 1.\n",
            "Was expecting:\n",
            "    \"Ontology\" ...\n",
            "     (Line 0)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: TurtleOntologyParser\n",
            "uk.ac.manchester.cs.owl.owlapi.turtle.parser.ParseException: Encountered \" <INTEGER> \"301 \"\" at line 2, column 14.\n",
            "Was expecting:\n",
            "    \".\" ...\n",
            "    \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: OWLOBOParser\n",
            "org.coode.owlapi.obo.parser.TokenMgrError: Lexical error at line 1, column 7.  Encountered: \"\\r\" (13), after : \"\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: KRSS2OWLParser\n",
            "de.uulm.ecs.ai.owlapi.krssparser.ParseException: Encountered \" \">\" \"<html> \"\" at line 1, column 1.\n",
            "Was expecting:\n",
            "    <EOF> \n",
            "    \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: ManchesterOWLSyntaxOntologyParser\n",
            "Encountered '<html>' at line 1 column 1.  Expected either 'Ontology:' or 'Prefix:' (Line 1)\n",
            "\n",
            "\n",
            "org.semanticweb.owlapi.model.UnloadableImportException: Could not load imported ontology: <http://www.w3.org/2002/07/owl#> Cause: Problem parsing http://www.w3.org/2002/07/owl#\n",
            "Could not parse ontology.  Either a suitable parser could not be found, or parsing failed.  See parser logs below for explanation.\n",
            "The following parsers were tried:\n",
            "1) RDFXMLParser\n",
            "2) OWLXMLParser\n",
            "3) OWLFunctionalSyntaxOWLParser\n",
            "4) TurtleOntologyParser\n",
            "5) OWLOBOParser\n",
            "6) KRSS2OWLParser\n",
            "7) ManchesterOWLSyntaxOntologyParser\n",
            "\n",
            "\n",
            "Detailed logs:\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: RDFXMLParser\n",
            "org.semanticweb.owlapi.rdf.syntax.RDFParserException: [line=1:column=7] Expecting rdf:RDF element.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: OWLXMLParser\n",
            "org.xml.sax.SAXParseException; systemId: http://www.w3.org/2002/07/owl#; lineNumber: 6; columnNumber: 3; The element type \"hr\" must be terminated by the matching end-tag \"</hr>\".\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: OWLFunctionalSyntaxOWLParser\n",
            "Encountered \" <FULLIRI> \"<html> \"\" at line 1, column 1.\n",
            "Was expecting:\n",
            "    \"Ontology\" ...\n",
            "     (Line 0)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: TurtleOntologyParser\n",
            "uk.ac.manchester.cs.owl.owlapi.turtle.parser.ParseException: Encountered \" <INTEGER> \"301 \"\" at line 2, column 14.\n",
            "Was expecting:\n",
            "    \".\" ...\n",
            "    \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: OWLOBOParser\n",
            "org.coode.owlapi.obo.parser.TokenMgrError: Lexical error at line 1, column 7.  Encountered: \"\\r\" (13), after : \"\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: KRSS2OWLParser\n",
            "de.uulm.ecs.ai.owlapi.krssparser.ParseException: Encountered \" \">\" \"<html> \"\" at line 1, column 1.\n",
            "Was expecting:\n",
            "    <EOF> \n",
            "    \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: ManchesterOWLSyntaxOntologyParser\n",
            "Encountered '<html>' at line 1 column 1.  Expected either 'Ontology:' or 'Prefix:' (Line 1)\n",
            "\n",
            "\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLOntologyManagerImpl.makeLoadImportRequest(OWLOntologyManagerImpl.java:1315)\n",
            "\tat org.coode.owlapi.rdfxml.parser.TPImportsHandler.handleTriple(TPImportsHandler.java:89)\n",
            "\tat org.coode.owlapi.rdfxml.parser.OWLRDFConsumer.handleStreaming(OWLRDFConsumer.java:1742)\n",
            "\tat org.coode.owlapi.rdfxml.parser.OWLRDFConsumer.statementWithResourceValue(OWLRDFConsumer.java:1701)\n",
            "\tat org.semanticweb.owlapi.rdf.syntax.RDFParser.statementWithResourceValue(RDFParser.java:573)\n",
            "\tat org.semanticweb.owlapi.rdf.syntax.RDFParser$EmptyPropertyElement.startElement(RDFParser.java:1045)\n",
            "\tat org.semanticweb.owlapi.rdf.syntax.RDFParser$PropertyElementList.startElement(RDFParser.java:916)\n",
            "\tat org.semanticweb.owlapi.rdf.syntax.RDFParser.startElement(RDFParser.java:281)\n",
            "\tat org.coode.owlapi.rdfxml.parser.RDFXMLParser$1.startElement(RDFXMLParser.java:91)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.startElement(AbstractSAXParser.java:510)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.parsers.AbstractXMLDocumentParser.emptyElement(AbstractXMLDocumentParser.java:183)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:351)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2710)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:605)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:112)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:534)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:888)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:824)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1216)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:635)\n",
            "\tat java.xml/com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl.parse(SAXParserImpl.java:324)\n",
            "\tat org.semanticweb.owlapi.rdf.syntax.RDFParser.parse(RDFParser.java:170)\n",
            "\tat org.coode.owlapi.rdfxml.parser.RDFXMLParser.parse(RDFXMLParser.java:119)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.ParsableOWLOntologyFactory.loadOWLOntology(ParsableOWLOntologyFactory.java:206)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLOntologyManagerImpl.loadOntology(OWLOntologyManagerImpl.java:880)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLOntologyManagerImpl.loadOntology(OWLOntologyManagerImpl.java:800)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLOntologyManagerImpl.loadOntology(OWLOntologyManagerImpl.java:758)\n",
            "\tat org.semanticweb.HermiT.cli.CommandLine.main(Unknown Source)\n",
            "Caused by: org.semanticweb.owlapi.io.UnparsableOntologyException: Problem parsing http://www.w3.org/2002/07/owl#\n",
            "Could not parse ontology.  Either a suitable parser could not be found, or parsing failed.  See parser logs below for explanation.\n",
            "The following parsers were tried:\n",
            "1) RDFXMLParser\n",
            "2) OWLXMLParser\n",
            "3) OWLFunctionalSyntaxOWLParser\n",
            "4) TurtleOntologyParser\n",
            "5) OWLOBOParser\n",
            "6) KRSS2OWLParser\n",
            "7) ManchesterOWLSyntaxOntologyParser\n",
            "\n",
            "\n",
            "Detailed logs:\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: RDFXMLParser\n",
            "org.semanticweb.owlapi.rdf.syntax.RDFParserException: [line=1:column=7] Expecting rdf:RDF element.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: OWLXMLParser\n",
            "org.xml.sax.SAXParseException; systemId: http://www.w3.org/2002/07/owl#; lineNumber: 6; columnNumber: 3; The element type \"hr\" must be terminated by the matching end-tag \"</hr>\".\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: OWLFunctionalSyntaxOWLParser\n",
            "Encountered \" <FULLIRI> \"<html> \"\" at line 1, column 1.\n",
            "Was expecting:\n",
            "    \"Ontology\" ...\n",
            "     (Line 0)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: TurtleOntologyParser\n",
            "uk.ac.manchester.cs.owl.owlapi.turtle.parser.ParseException: Encountered \" <INTEGER> \"301 \"\" at line 2, column 14.\n",
            "Was expecting:\n",
            "    \".\" ...\n",
            "    \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: OWLOBOParser\n",
            "org.coode.owlapi.obo.parser.TokenMgrError: Lexical error at line 1, column 7.  Encountered: \"\\r\" (13), after : \"\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: KRSS2OWLParser\n",
            "de.uulm.ecs.ai.owlapi.krssparser.ParseException: Encountered \" \">\" \"<html> \"\" at line 1, column 1.\n",
            "Was expecting:\n",
            "    <EOF> \n",
            "    \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Parser: ManchesterOWLSyntaxOntologyParser\n",
            "Encountered '<html>' at line 1 column 1.  Expected either 'Ontology:' or 'Prefix:' (Line 1)\n",
            "\n",
            "\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.ParsableOWLOntologyFactory.loadOWLOntology(ParsableOWLOntologyFactory.java:236)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLOntologyManagerImpl.loadOntology(OWLOntologyManagerImpl.java:880)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLOntologyManagerImpl.loadOntology(OWLOntologyManagerImpl.java:800)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLOntologyManagerImpl.loadImports(OWLOntologyManagerImpl.java:1278)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLOntologyManagerImpl.makeLoadImportRequest(OWLOntologyManagerImpl.java:1309)\n",
            "\t... 28 more\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Consistency Check with HermiT reasoner using HermiT.jar file download from: http://www.hermit-reasoner.com/\n",
        "#Change jar_path\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Verify the existence of Hermit.jar file\n",
        "jar_path = '/content/HermiT.jar'\n",
        "if not os.path.exists(jar_path):\n",
        "    print(f\"Error: The file {jar_path} does not exist.\")\n",
        "else:\n",
        "    # If the file exists, run the subprocess\n",
        "    hermit = subprocess.run(\n",
        "        [\"java\", \"-jar\", jar_path, '-k', xml_file_path],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    print(hermit.stdout)\n",
        "    print(hermit.stderr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pnuAYZ_1g-hl",
        "outputId": "39fe8f62-9e63-48e2-96c4-6c20f17e2057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "# Install Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbAWc_ouh7XS",
        "outputId": "b6de4690-00f6-46fb-f96e-f87e748d66b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.24\" 2024-07-16\n",
            "OpenJDK Runtime Environment (build 11.0.24+8-post-Ubuntu-1ubuntu322.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.24+8-post-Ubuntu-1ubuntu322.04, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set the path to the Java executable directly\n",
        "java_path = \"/usr/lib/jvm/java-11-openjdk-amd64/bin/java\"\n",
        "os.environ[\"JAVA_HOME\"] = java_path\n",
        "os.environ[\"PATH\"] += os.pathsep + java_path\n",
        "\n",
        "# Verify the Java version to ensure it's correctly set\n",
        "!{java_path} -version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2o0QhGK-X1O",
        "outputId": "96276000-ba85-43fa-aea1-482f587ebaeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: owlready2 in /usr/local/lib/python3.10/dist-packages (0.46)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install owlready2 --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfxe4tYKh7qM",
        "outputId": "4aafec35-3d24-448d-eaf6-e4d1ac40a8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ontology loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "* Owlready2 * Running HermiT...\n",
            "    java -Xmx2000M -cp /usr/local/lib/python3.10/dist-packages/owlready2/hermit:/usr/local/lib/python3.10/dist-packages/owlready2/hermit/HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:////tmp/tmpmujiaewd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred during reasoning: Java error message is:\n",
            "Exception in thread \"main\" java.lang.IllegalArgumentException: Error: In OWL 2 DL, owl:topDataProperty is only allowed to occur in the super property position of SubDataPropertyOf axioms, but the ontology contains an axiom DataPropertyDomain(owl:topDataProperty owl:Thing) that violates this condition.\n",
            "\tat org.semanticweb.HermiT.structural.OWLNormalization$AxiomVisitor.checkTopDataPropertyUse(Unknown Source)\n",
            "\tat org.semanticweb.HermiT.structural.OWLNormalization$AxiomVisitor.visit(Unknown Source)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLDataPropertyDomainAxiomImpl.accept(OWLDataPropertyDomainAxiomImpl.java:95)\n",
            "\tat org.semanticweb.HermiT.structural.OWLNormalization.processAxioms(Unknown Source)\n",
            "\tat org.semanticweb.HermiT.structural.OWLNormalization.processOntology(Unknown Source)\n",
            "\tat org.semanticweb.HermiT.structural.OWLClausification.preprocessAndClausify(Unknown Source)\n",
            "\tat org.semanticweb.HermiT.Reasoner.loadOntology(Reasoner.java:117)\n",
            "\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:108)\n",
            "\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:86)\n",
            "\tat org.semanticweb.HermiT.cli.CommandLine.main(CommandLine.java:830)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from owlready2 import *\n",
        "\n",
        "def load_ontology(file_path):\n",
        "    try:\n",
        "        onto = get_ontology(file_path).load()\n",
        "        print(\"Ontology loaded successfully.\")\n",
        "        return onto\n",
        "    except Exception as e:  # Broadened the exception catching to see any error\n",
        "        print(f\"Failed to load ontology due to parsing error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def check_for_inconsistencies(onto):\n",
        "    if onto is None:\n",
        "        print(\"No ontology loaded, skipping consistency check.\")\n",
        "        return\n",
        "\n",
        "    with onto:\n",
        "        try:\n",
        "            sync_reasoner()  # This invokes the reasoner and checks consistency\n",
        "            print(\"The ontology is consistent.\")\n",
        "        except OwlReadyInconsistentOntologyError:\n",
        "            print(\"The ontology has inconsistencies.\")\n",
        "        except Exception as e:  # Catching other possible exceptions\n",
        "            print(f\"An error occurred during reasoning: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    file_path = xml_file_path # Make sure this is the correct path\n",
        "    onto = load_ontology(file_path)\n",
        "    check_for_inconsistencies(onto)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn6n3SUyoeX6",
        "outputId": "d4747d38-c1c5-4569-b439-22ed5db6dbea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ontology loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "* Owlready2 * Running HermiT...\n",
            "    java -Xmx2000M -cp /usr/local/lib/python3.10/dist-packages/owlready2/hermit:/usr/local/lib/python3.10/dist-packages/owlready2/hermit/HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:////tmp/tmpyz7r0yux\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred during reasoning: Java error message is:\n",
            "Exception in thread \"main\" java.lang.IllegalArgumentException: Error: In OWL 2 DL, owl:topDataProperty is only allowed to occur in the super property position of SubDataPropertyOf axioms, but the ontology contains an axiom DataPropertyDomain(owl:topDataProperty owl:Thing) that violates this condition.\n",
            "\tat org.semanticweb.HermiT.structural.OWLNormalization$AxiomVisitor.checkTopDataPropertyUse(Unknown Source)\n",
            "\tat org.semanticweb.HermiT.structural.OWLNormalization$AxiomVisitor.visit(Unknown Source)\n",
            "\tat uk.ac.manchester.cs.owl.owlapi.OWLDataPropertyDomainAxiomImpl.accept(OWLDataPropertyDomainAxiomImpl.java:95)\n",
            "\tat org.semanticweb.HermiT.structural.OWLNormalization.processAxioms(Unknown Source)\n",
            "\tat org.semanticweb.HermiT.structural.OWLNormalization.processOntology(Unknown Source)\n",
            "\tat org.semanticweb.HermiT.structural.OWLClausification.preprocessAndClausify(Unknown Source)\n",
            "\tat org.semanticweb.HermiT.Reasoner.loadOntology(Reasoner.java:117)\n",
            "\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:108)\n",
            "\tat org.semanticweb.HermiT.Reasoner.<init>(Reasoner.java:86)\n",
            "\tat org.semanticweb.HermiT.cli.CommandLine.main(CommandLine.java:830)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#HermiT Reasoner\n",
        "from owlready2 import *\n",
        "\n",
        "def load_ontology(file_path):\n",
        "    try:\n",
        "        onto = get_ontology(file_path).load()\n",
        "        print(\"Ontology loaded successfully.\")\n",
        "        return onto\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load ontology due to parsing error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def check_for_inconsistencies(onto):\n",
        "    if onto is None:\n",
        "        print(\"No ontology loaded, skipping consistency check.\")\n",
        "        return\n",
        "\n",
        "    with onto:\n",
        "        try:\n",
        "            # Enabling debug information during reasoning\n",
        "            sync_reasoner(debug=True)  # Debug = True, to get consistency check results\n",
        "            print(\"The ontology is consistent.\")\n",
        "        except OwlReadyInconsistentOntologyError as e:\n",
        "            print(\"The ontology has inconsistencies.\")\n",
        "            print(f\"Debug information (if available): {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during reasoning: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    file_path = xml_file_path  # Make sure this is the correct path\n",
        "    onto = load_ontology(file_path)\n",
        "    check_for_inconsistencies(onto)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Eqn1uJn1rwlz",
        "outputId": "e297c383-9d25-45d3-8b08-77c5c257b03c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ontology loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "* Owlready2 * Running Pellet...\n",
            "    java -Xmx2000M -cp /usr/local/lib/python3.10/dist-packages/owlready2/pellet/owlapi-distribution-3.4.3-bin.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/httpcore-4.2.2.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/pellet-2.3.1.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/antlr-3.2.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/slf4j-log4j12-1.6.4.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/jena-arq-2.10.0.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/commons-codec-1.6.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/jgrapht-jdk1.5.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/jcl-over-slf4j-1.6.4.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/log4j-api-2.19.0.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/slf4j-api-1.6.4.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/jena-tdb-0.10.0.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/jena-core-2.10.0.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/httpclient-4.2.3.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/log4j-1.2-api-2.19.0.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/aterm-java-1.6.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/xercesImpl-2.10.0.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/antlr-runtime-3.2.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/jena-iri-0.9.5.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/xml-apis-1.4.01.jar:/usr/local/lib/python3.10/dist-packages/owlready2/pellet/log4j-core-2.19.0.jar pellet.Pellet realize --loader Jena --input-format N-Triples --infer-prop-values --infer-data-prop-values --ignore-imports /tmp/tmp5vnesq7d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Owlready * Adding relation owl.priorVersion relatedTo owl.priorVersion\n",
            "* Owlready * Adding relation owl.priorVersion isRelatedTo owl.priorVersion\n",
            "* Owlready * Adding relation owl.incompatibleWith relatedTo owl.incompatibleWith\n",
            "* Owlready * Adding relation owl.incompatibleWith isRelatedTo owl.incompatibleWith\n",
            "* Owlready * Adding relation owl.backwardCompatibleWith relatedTo owl.backwardCompatibleWith\n",
            "* Owlready * Adding relation owl.backwardCompatibleWith isRelatedTo owl.backwardCompatibleWith\n",
            "The ontology is consistent.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "* Owlready2 * Pellet took 2.9101271629333496 seconds\n",
            "* Owlready2 * Pellet output:\n",
            "\n",
            " http://www.w3.org/2002/07/owl#Thing = http://www.aquadiva.de/ontology#CO2FixationPathway = http://www.aquadiva.de/ontology#CyclingProcess = http://www.aquadiva.de/ontology#FixationPathway = http://www.aquadiva.de/ontology#NitrogenCyclingProcess - (http://www.w3.org/2002/07/owl, http://www.aquadiva.de/ontology#CO2_Fixation, http://dev.w3.org/cvsweb/2009/owl-grddl/owx2rdf.xsl, http://www.aquadiva.de/ontology#Photosynthesis, http://www.aquadiva.de/ontology#CalvinCycle, http://www.aquadiva.de/ontology#TerrestrialEcosystem)\n",
            "    http://www.aquadiva.de/ontology#BiochemicalProcess - (http://www.aquadiva.de/ontology#Methanogenesis)\n",
            "    http://www.aquadiva.de/ontology#BiogeochemicalCycle\n",
            "       http://www.aquadiva.de/ontology#NitrogenCycle - (http://www.aquadiva.de/ontology#NitrogenFixation)\n",
            "          http://www.aquadiva.de/ontology#Anammox\n",
            "          http://www.aquadiva.de/ontology#Denitrification - (http://www.aquadiva.de/ontology#BeechForest)\n",
            "          http://www.aquadiva.de/ontology#Nitrification\n",
            "             http://www.aquadiva.de/ontology#AmmoniaOxidation\n",
            "             http://www.aquadiva.de/ontology#NitriteOxidation\n",
            "          http://www.aquadiva.de/ontology#NitrogenFixation\n",
            "    http://www.aquadiva.de/ontology#C4Pathway\n",
            "    http://www.aquadiva.de/ontology#CAMPathway\n",
            "    http://www.aquadiva.de/ontology#CO2Fixation - (http://www.aquadiva.de/ontology#GreenhouseGasEmissions)\n",
            "    http://www.aquadiva.de/ontology#CalvinCycle\n",
            "    http://www.aquadiva.de/ontology#CarbonCycleComponent\n",
            "    http://www.aquadiva.de/ontology#CarbonCycling\n",
            "    http://www.aquadiva.de/ontology#CarbonIsotope\n",
            "    http://www.aquadiva.de/ontology#DenitrificationStep - (http://www.aquadiva.de/ontology#DenitrificationStep4, http://www.aquadiva.de/ontology#DenitrificationStep3, http://www.aquadiva.de/ontology#DenitrificationStep1, http://www.aquadiva.de/ontology#DenitrificationStep2)\n",
            "    http://www.aquadiva.de/ontology#Ecosystem\n",
            "       http://www.aquadiva.de/ontology#ForestEcosystem - (http://www.aquadiva.de/ontology#TropicalForest, http://www.aquadiva.de/ontology#TemperateForest, http://www.aquadiva.de/ontology#BeechForest)\n",
            "          http://www.aquadiva.de/ontology#BeechForest - (http://www.aquadiva.de/ontology#Nitrosomonas)\n",
            "          http://www.aquadiva.de/ontology#TemperateForest\n",
            "          http://www.aquadiva.de/ontology#TropicalForest\n",
            "    http://www.aquadiva.de/ontology#EnergyMetabolismProcess\n",
            "    http://www.aquadiva.de/ontology#EnvironmentalChange\n",
            "    http://www.aquadiva.de/ontology#EnvironmentalFactor - (http://www.aquadiva.de/ontology#BeechForest)\n",
            "    http://www.aquadiva.de/ontology#Enzyme - (http://www.aquadiva.de/ontology#Rubisco)\n",
            "    http://www.aquadiva.de/ontology#FixationProcess\n",
            "       http://www.aquadiva.de/ontology#NitrogenFixation\n",
            "    http://www.aquadiva.de/ontology#ForestHealth\n",
            "    http://www.aquadiva.de/ontology#ForestManagementPractice\n",
            "    http://www.aquadiva.de/ontology#ForestedArea - (http://www.aquadiva.de/ontology#TemperateForest)\n",
            "    http://www.aquadiva.de/ontology#Gas\n",
            "       http://www.aquadiva.de/ontology#TraceGas - (http://www.aquadiva.de/ontology#Methane)\n",
            "          http://www.aquadiva.de/ontology#CarbonDioxide\n",
            "          http://www.aquadiva.de/ontology#Methane\n",
            "          http://www.aquadiva.de/ontology#NitrousOxide\n",
            "    http://www.aquadiva.de/ontology#GroundwaterCondition\n",
            "    http://www.aquadiva.de/ontology#GroundwaterEcosystem - (http://www.aquadiva.de/ontology#AmmoniaOxidation)\n",
            "    http://www.aquadiva.de/ontology#GroundwaterQuality\n",
            "    http://www.aquadiva.de/ontology#IsotopeRatio\n",
            "    http://www.aquadiva.de/ontology#Isotope\n",
            "       http://www.aquadiva.de/ontology#NitrogenIsotope - (http://www.aquadiva.de/ontology#15N_Isotope)\n",
            "    http://www.aquadiva.de/ontology#Leaching\n",
            "       http://www.aquadiva.de/ontology#NitrogenLeaching - (http://www.aquadiva.de/ontology#NitrogenLeaching, http://www.aquadiva.de/ontology#GreenhouseGasEmissions)\n",
            "    http://www.aquadiva.de/ontology#MetabolicPathway\n",
            "    http://www.aquadiva.de/ontology#Metabolism\n",
            "       http://www.aquadiva.de/ontology#EnergyMetabolism - (http://www.aquadiva.de/ontology#MicrobialMetabolism)\n",
            "    http://www.aquadiva.de/ontology#MicroorganismGroup - (http://www.aquadiva.de/ontology#NitrogenCyclingMicroorganisms)\n",
            "    http://www.aquadiva.de/ontology#NitrogenCycleComponent\n",
            "    http://www.aquadiva.de/ontology#NitrogenCycling - (http://www.aquadiva.de/ontology#TropicalForest, http://www.aquadiva.de/ontology#CO2Fixation, http://www.aquadiva.de/ontology#AmmoniaOxidation)\n",
            "    http://www.aquadiva.de/ontology#NonForestedArea - (http://www.aquadiva.de/ontology#TemperateForest)\n",
            "    http://www.aquadiva.de/ontology#Organism\n",
            "       http://www.aquadiva.de/ontology#Microorganism\n",
            "          http://www.aquadiva.de/ontology#AmmoniaOxidizer - (http://www.aquadiva.de/ontology#Rubisco, http://www.aquadiva.de/ontology#Nitrosomonas)\n",
            "          http://www.aquadiva.de/ontology#DenitrifyingBacteria\n",
            "          http://www.aquadiva.de/ontology#Methanogens\n",
            "          http://www.aquadiva.de/ontology#NitriteOxidizer\n",
            "    http://www.aquadiva.de/ontology#Oxidizer\n",
            "       http://www.aquadiva.de/ontology#AmmoniaOxidizer - (http://www.aquadiva.de/ontology#Rubisco, http://www.aquadiva.de/ontology#Nitrosomonas)\n",
            "    http://www.aquadiva.de/ontology#Process\n",
            "       http://www.aquadiva.de/ontology#DenitrificationProcess - (http://www.aquadiva.de/ontology#DenitrificationProcess1)\n",
            "    http://www.aquadiva.de/ontology#Rubisco - (http://www.aquadiva.de/ontology#DenitrificationProcess1)\n",
            "    http://www.aquadiva.de/ontology#Soil - (http://www.aquadiva.de/ontology#ForestSoil)\n",
            "    http://www.aquadiva.de/ontology#Species\n",
            "    http://www.aquadiva.de/ontology#TraceGasConsumption\n",
            "    http://www.aquadiva.de/ontology#TraceGasEmission\n",
            "    http://www.aquadiva.de/ontology#TraceGasProduction - (http://www.aquadiva.de/ontology#NitrogenLeaching)\n",
            "    http://www.w3.org/1999/02/22-rdf-syntax-ns#Property\n",
            "       http://www.w3.org/2000/01/rdf-schema#ContainerMembershipProperty\n",
            "       http://www.w3.org/2002/07/owl#AnnotationProperty\n",
            "       http://www.w3.org/2002/07/owl#DatatypeProperty\n",
            "       http://www.w3.org/2002/07/owl#DeprecatedProperty\n",
            "       http://www.w3.org/2002/07/owl#FunctionalProperty\n",
            "       http://www.w3.org/2002/07/owl#ObjectProperty\n",
            "          http://www.w3.org/2002/07/owl#AsymmetricProperty\n",
            "          http://www.w3.org/2002/07/owl#InverseFunctionalProperty\n",
            "          http://www.w3.org/2002/07/owl#IrreflexiveProperty\n",
            "          http://www.w3.org/2002/07/owl#ReflexiveProperty\n",
            "          http://www.w3.org/2002/07/owl#SymmetricProperty\n",
            "          http://www.w3.org/2002/07/owl#TransitiveProperty\n",
            "       http://www.w3.org/2002/07/owl#OntologyProperty - (http://www.w3.org/2002/07/owl#incompatibleWith, http://www.w3.org/2002/07/owl#versionIRI, http://www.w3.org/2002/07/owl#imports, http://www.w3.org/2002/07/owl#backwardCompatibleWith, http://www.w3.org/2002/07/owl#priorVersion)\n",
            "    http://www.w3.org/2000/01/rdf-schema#Resource\n",
            "       http://www.w3.org/2000/01/rdf-schema#Class\n",
            "          http://www.w3.org/2000/01/rdf-schema#Datatype\n",
            "             http://www.w3.org/2002/07/owl#DataRange\n",
            "          http://www.w3.org/2002/07/owl#Class\n",
            "             http://www.w3.org/2002/07/owl#Restriction\n",
            "          http://www.w3.org/2002/07/owl#DeprecatedClass\n",
            "       http://www.w3.org/2000/01/rdf-schema#Container\n",
            "       http://www.w3.org/2000/01/rdf-schema#Literal\n",
            "       http://www.w3.org/2002/07/owl#AllDifferent\n",
            "       http://www.w3.org/2002/07/owl#AllDisjointClasses\n",
            "       http://www.w3.org/2002/07/owl#AllDisjointProperties\n",
            "       http://www.w3.org/2002/07/owl#Annotation\n",
            "       http://www.w3.org/2002/07/owl#Axiom\n",
            "       http://www.w3.org/2002/07/owl#NegativePropertyAssertion\n",
            "       http://www.w3.org/2002/07/owl#Ontology\n",
            "    http://www.w3.org/2002/07/owl#NamedIndividual\n",
            "\n",
            "PROPINST: http://www.aquadiva.de/ontology#CO2Fixation http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#CO2Fixation\n",
            "PROPINST: http://www.aquadiva.de/ontology#CO2Fixation http://www.aquadiva.de/ontology#hasRole http://www.aquadiva.de/ontology#Rubisco\n",
            "PROPINST: http://www.aquadiva.de/ontology#CO2Fixation http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#CO2Fixation\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationStep3 http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#DenitrificationStep3\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationStep3 http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#DenitrificationStep3\n",
            "PROPINST: http://www.w3.org/2002/07/owl#versionIRI http://www.aquadiva.de/ontology#relatedTo http://www.w3.org/2002/07/owl#versionIRI\n",
            "PROPINST: http://www.w3.org/2002/07/owl#versionIRI http://www.aquadiva.de/ontology#isRelatedTo http://www.w3.org/2002/07/owl#versionIRI\n",
            "PROPINST: http://www.aquadiva.de/ontology#TemperateForest http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#TemperateForest\n",
            "PROPINST: http://www.aquadiva.de/ontology#TemperateForest http://www.aquadiva.de/ontology#isDifferedBy http://www.aquadiva.de/ontology#TropicalForest\n",
            "PROPINST: http://www.aquadiva.de/ontology#TemperateForest http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#TemperateForest\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationStep1 http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#DenitrificationStep1\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationStep1 http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#DenitrificationStep1\n",
            "PROPINST: http://www.aquadiva.de/ontology#NitrogenCyclingMicroorganisms http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#NitrogenCyclingMicroorganisms\n",
            "PROPINST: http://www.aquadiva.de/ontology#NitrogenCyclingMicroorganisms http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#NitrogenCyclingMicroorganisms\n",
            "PROPINST: http://www.w3.org/2002/07/owl http://www.aquadiva.de/ontology#relatedTo http://www.w3.org/2002/07/owl\n",
            "PROPINST: http://www.w3.org/2002/07/owl http://www.w3.org/2003/g/data-view#namespaceTransformation http://dev.w3.org/cvsweb/2009/owl-grddl/owx2rdf.xsl\n",
            "PROPINST: http://www.w3.org/2002/07/owl http://www.aquadiva.de/ontology#isRelatedTo http://www.w3.org/2002/07/owl\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationStep4 http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#DenitrificationStep4\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationStep4 http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#DenitrificationStep4\n",
            "PROPINST: http://www.aquadiva.de/ontology#CO2_Fixation http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#CO2_Fixation\n",
            "PROPINST: http://www.aquadiva.de/ontology#CO2_Fixation http://www.aquadiva.de/ontology#keyPathwayIn http://www.aquadiva.de/ontology#Photosynthesis\n",
            "PROPINST: http://www.aquadiva.de/ontology#CO2_Fixation http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#CO2_Fixation\n",
            "PROPINST: http://www.aquadiva.de/ontology#NitrogenFixation http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#NitrogenFixation\n",
            "PROPINST: http://www.aquadiva.de/ontology#NitrogenFixation http://www.aquadiva.de/ontology#keyPathwayIn http://www.aquadiva.de/ontology#TerrestrialEcosystem\n",
            "PROPINST: http://www.aquadiva.de/ontology#NitrogenFixation http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#NitrogenFixation\n",
            "PROPINST: http://www.w3.org/2002/07/owl#imports http://www.aquadiva.de/ontology#relatedTo http://www.w3.org/2002/07/owl#imports\n",
            "PROPINST: http://www.w3.org/2002/07/owl#imports http://www.aquadiva.de/ontology#isRelatedTo http://www.w3.org/2002/07/owl#imports\n",
            "PROPINST: http://www.aquadiva.de/ontology#Rubisco http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#Rubisco\n",
            "PROPINST: http://www.aquadiva.de/ontology#Rubisco http://www.aquadiva.de/ontology#roleIn http://www.aquadiva.de/ontology#CO2Fixation\n",
            "PROPINST: http://www.aquadiva.de/ontology#Rubisco http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#Rubisco\n",
            "PROPINST: http://www.aquadiva.de/ontology#AmmoniaOxidation http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#AmmoniaOxidation\n",
            "PROPINST: http://www.aquadiva.de/ontology#AmmoniaOxidation http://www.aquadiva.de/ontology#hasRolePlayedBy http://www.aquadiva.de/ontology#Nitrosomonas\n",
            "PROPINST: http://www.aquadiva.de/ontology#AmmoniaOxidation http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#AmmoniaOxidation\n",
            "PROPINST: http://www.aquadiva.de/ontology#NitrogenLeaching http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#NitrogenLeaching\n",
            "PROPINST: http://www.aquadiva.de/ontology#NitrogenLeaching http://www.aquadiva.de/ontology#isInfluencedBy http://www.aquadiva.de/ontology#BeechForest\n",
            "PROPINST: http://www.aquadiva.de/ontology#NitrogenLeaching http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#NitrogenLeaching\n",
            "PROPINST: http://www.w3.org/2002/07/owl#priorVersion http://www.aquadiva.de/ontology#relatedTo http://www.w3.org/2002/07/owl#priorVersion\n",
            "PROPINST: http://www.w3.org/2002/07/owl#priorVersion http://www.aquadiva.de/ontology#isRelatedTo http://www.w3.org/2002/07/owl#priorVersion\n",
            "PROPINST: http://www.aquadiva.de/ontology#BeechForest http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#BeechForest\n",
            "PROPINST: http://www.aquadiva.de/ontology#BeechForest http://www.aquadiva.de/ontology#influences http://www.aquadiva.de/ontology#NitrogenLeaching\n",
            "PROPINST: http://www.aquadiva.de/ontology#BeechForest http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#BeechForest\n",
            "PROPINST: http://www.aquadiva.de/ontology#GreenhouseGasEmissions http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#GreenhouseGasEmissions\n",
            "PROPINST: http://www.aquadiva.de/ontology#GreenhouseGasEmissions http://www.aquadiva.de/ontology#hasContribution http://www.aquadiva.de/ontology#DenitrificationProcess1\n",
            "PROPINST: http://www.aquadiva.de/ontology#GreenhouseGasEmissions http://www.aquadiva.de/ontology#isContributionOf http://www.aquadiva.de/ontology#DenitrificationProcess1\n",
            "PROPINST: http://www.aquadiva.de/ontology#GreenhouseGasEmissions http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#GreenhouseGasEmissions\n",
            "PROPINST: http://www.aquadiva.de/ontology#15N_Isotope http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#15N_Isotope\n",
            "PROPINST: http://www.aquadiva.de/ontology#15N_Isotope http://www.aquadiva.de/ontology#foundIn http://www.aquadiva.de/ontology#ForestSoil\n",
            "PROPINST: http://www.aquadiva.de/ontology#15N_Isotope http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#15N_Isotope\n",
            "PROPINST: http://www.aquadiva.de/ontology#Nitrosomonas http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#Nitrosomonas\n",
            "PROPINST: http://www.aquadiva.de/ontology#Nitrosomonas http://www.aquadiva.de/ontology#playsRoleIn http://www.aquadiva.de/ontology#AmmoniaOxidation\n",
            "PROPINST: http://www.aquadiva.de/ontology#Nitrosomonas http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#Nitrosomonas\n",
            "PROPINST: http://www.aquadiva.de/ontology#ForestSoil http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#ForestSoil\n",
            "PROPINST: http://www.aquadiva.de/ontology#ForestSoil http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#ForestSoil\n",
            "PROPINST: http://www.aquadiva.de/ontology#Methane http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#Methane\n",
            "PROPINST: http://www.aquadiva.de/ontology#Methane http://www.aquadiva.de/ontology#producedDuring http://www.aquadiva.de/ontology#Methanogenesis\n",
            "PROPINST: http://www.aquadiva.de/ontology#Methane http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#Methane\n",
            "PROPINST: http://dev.w3.org/cvsweb/2009/owl-grddl/owx2rdf.xsl http://www.aquadiva.de/ontology#relatedTo http://dev.w3.org/cvsweb/2009/owl-grddl/owx2rdf.xsl\n",
            "PROPINST: http://dev.w3.org/cvsweb/2009/owl-grddl/owx2rdf.xsl http://www.aquadiva.de/ontology#isRelatedTo http://dev.w3.org/cvsweb/2009/owl-grddl/owx2rdf.xsl\n",
            "PROPINST: http://www.aquadiva.de/ontology#Photosynthesis http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#Photosynthesis\n",
            "PROPINST: http://www.aquadiva.de/ontology#Photosynthesis http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#Photosynthesis\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationStep2 http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#DenitrificationStep2\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationStep2 http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#DenitrificationStep2\n",
            "PROPINST: http://www.aquadiva.de/ontology#TropicalForest http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#TropicalForest\n",
            "PROPINST: http://www.aquadiva.de/ontology#TropicalForest http://www.aquadiva.de/ontology#differsBetween http://www.aquadiva.de/ontology#TemperateForest\n",
            "PROPINST: http://www.aquadiva.de/ontology#TropicalForest http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#TropicalForest\n",
            "PROPINST: http://www.aquadiva.de/ontology#CalvinCycle http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#CalvinCycle\n",
            "PROPINST: http://www.aquadiva.de/ontology#CalvinCycle http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#CalvinCycle\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationProcess1 http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#DenitrificationProcess1\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationProcess1 http://www.aquadiva.de/ontology#contributesTo http://www.aquadiva.de/ontology#GreenhouseGasEmissions\n",
            "PROPINST: http://www.aquadiva.de/ontology#DenitrificationProcess1 http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#DenitrificationProcess1\n",
            "PROPINST: http://www.w3.org/2002/07/owl#incompatibleWith http://www.aquadiva.de/ontology#relatedTo http://www.w3.org/2002/07/owl#incompatibleWith\n",
            "PROPINST: http://www.w3.org/2002/07/owl#incompatibleWith http://www.aquadiva.de/ontology#isRelatedTo http://www.w3.org/2002/07/owl#incompatibleWith\n",
            "PROPINST: http://www.aquadiva.de/ontology#TerrestrialEcosystem http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#TerrestrialEcosystem\n",
            "PROPINST: http://www.aquadiva.de/ontology#TerrestrialEcosystem http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#TerrestrialEcosystem\n",
            "PROPINST: http://www.aquadiva.de/ontology#MicrobialMetabolism http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#MicrobialMetabolism\n",
            "PROPINST: http://www.aquadiva.de/ontology#MicrobialMetabolism http://www.aquadiva.de/ontology#variesAmong http://www.aquadiva.de/ontology#NitrogenCyclingMicroorganisms\n",
            "PROPINST: http://www.aquadiva.de/ontology#MicrobialMetabolism http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#MicrobialMetabolism\n",
            "PROPINST: http://www.w3.org/2002/07/owl#backwardCompatibleWith http://www.aquadiva.de/ontology#relatedTo http://www.w3.org/2002/07/owl#backwardCompatibleWith\n",
            "PROPINST: http://www.w3.org/2002/07/owl#backwardCompatibleWith http://www.aquadiva.de/ontology#isRelatedTo http://www.w3.org/2002/07/owl#backwardCompatibleWith\n",
            "PROPINST: http://www.aquadiva.de/ontology#Methanogenesis http://www.aquadiva.de/ontology#relatedTo http://www.aquadiva.de/ontology#Methanogenesis\n",
            "PROPINST: http://www.aquadiva.de/ontology#Methanogenesis http://www.aquadiva.de/ontology#hasProduction http://www.aquadiva.de/ontology#Methane\n",
            "PROPINST: http://www.aquadiva.de/ontology#Methanogenesis http://www.aquadiva.de/ontology#isRelatedTo http://www.aquadiva.de/ontology#Methanogenesis\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#DenitrificationStep3 http://www.aquadiva.de/ontology#hasDenitrificationStepName literal(Nitric Oxide Reduction,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#TemperateForest http://www.aquadiva.de/ontology#hasForestType literal(Temperate,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#DenitrificationStep1 http://www.aquadiva.de/ontology#hasDenitrificationStepName literal(Nitrate Reduction,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#NitrogenCyclingMicroorganisms http://www.aquadiva.de/ontology#hasMicroorganismGroupName literal(Nitrogen-Cycling Microorganisms,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.w3.org/2002/07/owl http://purl.org/dc/elements/1.1/title literal(The OWL 2 Schema vocabulary (OWL 2),(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#DenitrificationStep4 http://www.aquadiva.de/ontology#hasDenitrificationStepName literal(Nitrous Oxide Reduction,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#CO2_Fixation http://www.aquadiva.de/ontology#hasFixationPathway literal(Calvin Cycle,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#NitrogenFixation http://www.aquadiva.de/ontology#hasNitrogenCycleType literal(Nitrogen Fixation,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#Rubisco http://www.aquadiva.de/ontology#hasEnzymeName literal(Ribulose-1,5-bisphosphate carboxylase/oxygenase,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#BeechForest http://www.aquadiva.de/ontology#hasForestType literal(Beech,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#15N_Isotope http://www.aquadiva.de/ontology#hasNitrogenIsotopeValue literal(0.3663,(),http://www.w3.org/2001/XMLSchema#decimal)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#Nitrosomonas http://www.aquadiva.de/ontology#hasAmmoniaOxidizerSpecies literal(Nitrosomonas europaea,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#ForestSoil http://www.aquadiva.de/ontology#hasSoilType literal(Forest Soil,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#Methane http://www.aquadiva.de/ontology#hasTraceGasType literal(CH4,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#DenitrificationStep2 http://www.aquadiva.de/ontology#hasDenitrificationStepName literal(Nitrite Reduction,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#TropicalForest http://www.aquadiva.de/ontology#hasForestType literal(Tropical,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#CalvinCycle http://www.aquadiva.de/ontology#hasFixationPathway literal(Calvin Cycle,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#DenitrificationProcess1 http://www.aquadiva.de/ontology#hasDenitrificationRate literal(1.5,(),http://www.w3.org/2001/XMLSchema#decimal)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#MicrobialMetabolism http://www.aquadiva.de/ontology#hasMetabolicRate literal(2.3,(),http://www.w3.org/2001/XMLSchema#decimal)\n",
            "DATAPROPVAL: http://www.aquadiva.de/ontology#Methanogenesis http://www.aquadiva.de/ontology#hasBiochemicalProcessName literal(Methanogenesis,(),http://www.w3.org/2001/XMLSchema#string)\n",
            "\n",
            "* Owlready * Equivalenting: owl.Thing ontology.CO2FixationPathway\n",
            "* Owlready * Equivalenting: owl.Thing ontology.CyclingProcess\n",
            "* Owlready * Equivalenting: owl.Thing ontology.FixationPathway\n",
            "* Owlready * Equivalenting: owl.Thing ontology.NitrogenCyclingProcess\n",
            "* Owlready * Equivalenting: ontology.CO2FixationPathway owl.Thing\n",
            "* Owlready * Equivalenting: ontology.CO2FixationPathway ontology.CyclingProcess\n",
            "* Owlready * Equivalenting: ontology.CO2FixationPathway ontology.FixationPathway\n",
            "* Owlready * Equivalenting: ontology.CO2FixationPathway ontology.NitrogenCyclingProcess\n",
            "* Owlready * Equivalenting: ontology.CyclingProcess owl.Thing\n",
            "* Owlready * Equivalenting: ontology.CyclingProcess ontology.CO2FixationPathway\n",
            "* Owlready * Equivalenting: ontology.CyclingProcess ontology.FixationPathway\n",
            "* Owlready * Equivalenting: ontology.CyclingProcess ontology.NitrogenCyclingProcess\n",
            "* Owlready * Equivalenting: ontology.FixationPathway owl.Thing\n",
            "* Owlready * Equivalenting: ontology.FixationPathway ontology.CO2FixationPathway\n",
            "* Owlready * Equivalenting: ontology.FixationPathway ontology.CyclingProcess\n",
            "* Owlready * Equivalenting: ontology.FixationPathway ontology.NitrogenCyclingProcess\n",
            "* Owlready * Equivalenting: ontology.NitrogenCyclingProcess owl.Thing\n",
            "* Owlready * Equivalenting: ontology.NitrogenCyclingProcess ontology.CO2FixationPathway\n",
            "* Owlready * Equivalenting: ontology.NitrogenCyclingProcess ontology.CyclingProcess\n",
            "* Owlready * Equivalenting: ontology.NitrogenCyclingProcess ontology.FixationPathway\n",
            "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
          ]
        }
      ],
      "source": [
        "#Pellet Reasoner\n",
        "from owlready2 import *\n",
        "\n",
        "def load_ontology(file_path):\n",
        "    try:\n",
        "        onto = get_ontology(file_path).load()\n",
        "        print(\"Ontology loaded successfully.\")\n",
        "        return onto\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load ontology due to parsing error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def check_for_inconsistencies(onto):\n",
        "    if onto is None:\n",
        "        print(\"No ontology loaded, skipping consistency check.\")\n",
        "        return\n",
        "\n",
        "    with onto:\n",
        "        try:\n",
        "            # Using Pellet reasoner to check consistency and infer knowledge\n",
        "            # Set debug level to 2 for detailed explanations\n",
        "            sync_reasoner_pellet(infer_property_values=True, infer_data_property_values=True, debug=2)\n",
        "            print(\"The ontology is consistent.\")\n",
        "        except OwlReadyInconsistentOntologyError:\n",
        "            print(\"The ontology has inconsistencies.\")\n",
        "            # Additional explanations will be output due to debug=2\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during reasoning with Pellet: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    file_path = xml_file_path  # Update this path to your file\n",
        "    onto = load_ontology(file_path)\n",
        "    check_for_inconsistencies(onto)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "urF1L_d6wHJr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjv-C7Xpiv00"
      },
      "source": [
        "# Common Pitfall Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qvoG1P23XI4q"
      },
      "outputs": [],
      "source": [
        "# Common Pitfall check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vfbmwYpdySm",
        "outputId": "4a0c6565-098b-4eaa-e797-a1ff76987b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "from rdflib import Graph, URIRef, RDF, RDFS, OWL\n",
        "import rdflib\n",
        "\n",
        "class OntologyPitfallDetector:\n",
        "    def __init__(self, turtle_file):\n",
        "        self.graph = Graph()\n",
        "        self.graph.parse(turtle_file, format=\"turtle\")\n",
        "        self.pitfalls = []\n",
        "\n",
        "    def detect_missing_labels(self):\n",
        "        # Check for classes and properties without rdfs:label\n",
        "        for s in self.graph.subjects(RDF.type, RDFS.Class):\n",
        "            if not (s, RDFS.label, None) in self.graph:\n",
        "                self.pitfalls.append(f\"Class {s} is missing an rdfs:label.\")\n",
        "\n",
        "        for s in self.graph.subjects(RDF.type, RDF.Property):\n",
        "            if not (s, RDFS.label, None) in self.graph:\n",
        "                self.pitfalls.append(f\"Property {s} is missing an rdfs:label.\")\n",
        "\n",
        "    def detect_unconnected_classes(self):\n",
        "        # Check for classes not used in any triple\n",
        "        for s in self.graph.subjects(RDF.type, RDFS.Class):\n",
        "            if not (None, None, s) in self.graph and not (s, None, None) in self.graph:\n",
        "                self.pitfalls.append(f\"Class {s} is not connected to any other resources.\")\n",
        "\n",
        "    def detect_cyclic_subclassing(self):\n",
        "        # Detect cyclic subclassing\n",
        "        def detect_cycle(start, graph, visited, stack):\n",
        "            visited.add(start)\n",
        "            stack.add(start)\n",
        "            for subclass in graph.objects(start, RDFS.subClassOf):\n",
        "                if subclass not in visited:\n",
        "                    if detect_cycle(subclass, graph, visited, stack):\n",
        "                        return True\n",
        "                elif subclass in stack:\n",
        "                    return True\n",
        "            stack.remove(start)\n",
        "            return False\n",
        "\n",
        "        visited = set()\n",
        "        stack = set()\n",
        "        for cls in self.graph.subjects(RDF.type, RDFS.Class):\n",
        "            if cls not in visited:\n",
        "                if detect_cycle(cls, self.graph, visited, stack):\n",
        "                    self.pitfalls.append(f\"Cyclic subclassing detected involving {cls}.\")\n",
        "\n",
        "    def detect_missing_disjointness(self):\n",
        "        # Check for classes that are not explicitly disjoint\n",
        "        classes = list(self.graph.subjects(RDF.type, RDFS.Class))\n",
        "        for i, cls1 in enumerate(classes):\n",
        "            for cls2 in classes[i+1:]:\n",
        "                if (cls1, OWL.disjointWith, cls2) not in self.graph and (cls2, OWL.disjointWith, cls1) not in self.graph:\n",
        "                    # Check if the two classes have any intersection instances\n",
        "                    instances_cls1 = set(self.graph.subjects(RDF.type, cls1))\n",
        "                    instances_cls2 = set(self.graph.subjects(RDF.type, cls2))\n",
        "                    if instances_cls1 & instances_cls2:\n",
        "                        self.pitfalls.append(f\"Classes {cls1} and {cls2} are missing disjointness and have overlapping instances.\")\n",
        "\n",
        "    def detect_all_pitfalls(self):\n",
        "        self.detect_missing_labels()\n",
        "        self.detect_unconnected_classes()\n",
        "        self.detect_cyclic_subclassing()\n",
        "        self.detect_missing_disjointness()\n",
        "        return self.pitfalls\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    turtle_ontology_path = turtle_ontology_path  # Update this path to your Turtle file\n",
        "    detector = OntologyPitfallDetector(turtle_ontology_path)\n",
        "\n",
        "    pitfalls = detector.detect_all_pitfalls()\n",
        "    print(len(pitfalls))\n",
        "    for pitfall in pitfalls:\n",
        "        print(pitfall)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rdflib\n",
        "\n",
        "def merge_ontologies(file1, file2, output_file):\n",
        "    # Create an RDF graph\n",
        "    g = rdflib.Graph()\n",
        "\n",
        "    # Parse the first ontology file\n",
        "    g.parse(file1, format='turtle')\n",
        "\n",
        "    # Parse the second ontology file\n",
        "    g.parse(file2, format='turtle')\n",
        "\n",
        "    # Serialize and write the merged graph to a new file\n",
        "    g.serialize(destination=output_file, format='turtle')\n",
        "    print(f\"Merged ontology saved to {output_file}\")\n",
        "\n",
        "# Example usage:\n",
        "merge_ontologies('/content/AquaDiva2.ttl', '/content/AquaDiva4.ttl', '/content/AquaDivaMergedNew.ttl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "0FVz5SbnwfdK",
        "outputId": "dd5d3e31-b385-47a7-f739-2a99940cd07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/AquaDiva2.ttl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-993faae107c1>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmerge_ontologies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/AquaDiva2.ttl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/AquaDiva4.ttl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/AquaDivaMergedNew.ttl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-993faae107c1>\u001b[0m in \u001b[0;36mmerge_ontologies\u001b[0;34m(file1, file2, output_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Parse the first ontology file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'turtle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Parse the second ontology file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, publicID, format, location, file, data, **args)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \"\"\"\n\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m         source = create_input_source(\n\u001b[0m\u001b[1;32m   1469\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mpublicID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpublicID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/parser.py\u001b[0m in \u001b[0;36mcreate_input_source\u001b[0;34m(source, publicID, location, file, data, format)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0minput_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_input_source_from_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/parser.py\u001b[0m in \u001b[0;36m_create_input_source_from_location\u001b[0;34m(file, format, input_source, location)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mabsolute_location\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file:///\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl2pathname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabsolute_location\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file:///\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0minput_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mURLInputSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabsolute_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/AquaDiva2.ttl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m1qJF0S8wuqJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}